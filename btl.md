## Bayesian Transfer Learning
Transfer learning is the process of using knowledge learned from one or more source tasks, to help increase the learning rate of another target learning task. Take for example a pianist learning the organ. The pianist already knows the fundamentals of sheet music and other related skills. We would then expect that they would learn the organ faster relative to another person who had no musical experience. Transfer learning attempts to bring this knowledge transfer into an AI context.

This research looks at the case of transfer learning in a Bayesian setting. Bayesian statistics is a technology that allows for the processing of knowledge and data into a personal belief of an unknown object of interest in a mathematically justified manner. While investigations into transfer learning in a Bayesian setting in research exists,  it is far more common to employ more traditional *black box* methods which rely on an algorithm finding correlations and patterns between different inputs in a hard to  interpret way. More specifically, this research looks at an assumption that most Bayesian transfer learning methods make about how the underlying relationships between different tasks relate to each other. This dissertation attempts to define a framework which does not make any assumptions on theses relationships.


## Background Techniques
### Distributed Opinion Pooling
A mechanism for merging knowledge from multiple experts. Finds the distribution on an unknown object of interest \\[ f^{\circ} \equiv f^{\circ}(x)=\sum_{i=1}^{m}\left[f_{i}(x)\right]^{w_{i}}\\]